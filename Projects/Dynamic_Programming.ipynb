{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Reinforcement Learning: Dynamic Programming**"
      ],
      "metadata": {
        "id": "bZ-Q3FKltfNF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsGqubiDkQnd"
      },
      "source": [
        "import gym"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iS40R9okStg"
      },
      "source": [
        "gym.envs.register(\n",
        "    id='FrozenLakeNotSlippery-v0',\n",
        "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
        "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
        "    max_episode_steps=100,\n",
        "    reward_threshold=0.74\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVX1AjRWkueO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3cb631-aae9-4738-bbed-50454c01060a"
      },
      "source": [
        "env=gym.make('FrozenLakeNotSlippery-v0')\n",
        "env.env.P"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: {0: [(1.0, 0, 0.0, False)],\n",
              "  1: [(1.0, 4, 0.0, False)],\n",
              "  2: [(1.0, 1, 0.0, False)],\n",
              "  3: [(1.0, 0, 0.0, False)]},\n",
              " 1: {0: [(1.0, 0, 0.0, False)],\n",
              "  1: [(1.0, 5, 0.0, True)],\n",
              "  2: [(1.0, 2, 0.0, False)],\n",
              "  3: [(1.0, 1, 0.0, False)]},\n",
              " 2: {0: [(1.0, 1, 0.0, False)],\n",
              "  1: [(1.0, 6, 0.0, False)],\n",
              "  2: [(1.0, 3, 0.0, False)],\n",
              "  3: [(1.0, 2, 0.0, False)]},\n",
              " 3: {0: [(1.0, 2, 0.0, False)],\n",
              "  1: [(1.0, 7, 0.0, True)],\n",
              "  2: [(1.0, 3, 0.0, False)],\n",
              "  3: [(1.0, 3, 0.0, False)]},\n",
              " 4: {0: [(1.0, 4, 0.0, False)],\n",
              "  1: [(1.0, 8, 0.0, False)],\n",
              "  2: [(1.0, 5, 0.0, True)],\n",
              "  3: [(1.0, 0, 0.0, False)]},\n",
              " 5: {0: [(1.0, 5, 0, True)],\n",
              "  1: [(1.0, 5, 0, True)],\n",
              "  2: [(1.0, 5, 0, True)],\n",
              "  3: [(1.0, 5, 0, True)]},\n",
              " 6: {0: [(1.0, 5, 0.0, True)],\n",
              "  1: [(1.0, 10, 0.0, False)],\n",
              "  2: [(1.0, 7, 0.0, True)],\n",
              "  3: [(1.0, 2, 0.0, False)]},\n",
              " 7: {0: [(1.0, 7, 0, True)],\n",
              "  1: [(1.0, 7, 0, True)],\n",
              "  2: [(1.0, 7, 0, True)],\n",
              "  3: [(1.0, 7, 0, True)]},\n",
              " 8: {0: [(1.0, 8, 0.0, False)],\n",
              "  1: [(1.0, 12, 0.0, True)],\n",
              "  2: [(1.0, 9, 0.0, False)],\n",
              "  3: [(1.0, 4, 0.0, False)]},\n",
              " 9: {0: [(1.0, 8, 0.0, False)],\n",
              "  1: [(1.0, 13, 0.0, False)],\n",
              "  2: [(1.0, 10, 0.0, False)],\n",
              "  3: [(1.0, 5, 0.0, True)]},\n",
              " 10: {0: [(1.0, 9, 0.0, False)],\n",
              "  1: [(1.0, 14, 0.0, False)],\n",
              "  2: [(1.0, 11, 0.0, True)],\n",
              "  3: [(1.0, 6, 0.0, False)]},\n",
              " 11: {0: [(1.0, 11, 0, True)],\n",
              "  1: [(1.0, 11, 0, True)],\n",
              "  2: [(1.0, 11, 0, True)],\n",
              "  3: [(1.0, 11, 0, True)]},\n",
              " 12: {0: [(1.0, 12, 0, True)],\n",
              "  1: [(1.0, 12, 0, True)],\n",
              "  2: [(1.0, 12, 0, True)],\n",
              "  3: [(1.0, 12, 0, True)]},\n",
              " 13: {0: [(1.0, 12, 0.0, True)],\n",
              "  1: [(1.0, 13, 0.0, False)],\n",
              "  2: [(1.0, 14, 0.0, False)],\n",
              "  3: [(1.0, 9, 0.0, False)]},\n",
              " 14: {0: [(1.0, 13, 0.0, False)],\n",
              "  1: [(1.0, 14, 0.0, False)],\n",
              "  2: [(1.0, 15, 1.0, True)],\n",
              "  3: [(1.0, 10, 0.0, False)]},\n",
              " 15: {0: [(1.0, 15, 0, True)],\n",
              "  1: [(1.0, 15, 0, True)],\n",
              "  2: [(1.0, 15, 0, True)],\n",
              "  3: [(1.0, 15, 0, True)]}}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcL5SOZqZp0E"
      },
      "source": [
        "We can clearly see that P is a list of dictionaries, which stores all the information of the States (from state 0 to state 15). In each state, we can find the key of the dictionary (0, 1, 2, 3) represents the actions we can take (0:left, 1:down, 2:right, 3:up). For each actions in the state, there exist four elements. The second element contains the next state (after taking this action). The third element stores the reward (if the next state is 15, it get the reward 1, otherwise is 0). The last element is a boolean to check if the game is over (reach the last place 15 or lose the game). The first element is all ones in this case, so we don't know what exactly it is. However, it could be the probability that the agent would take this action. If it is played by human, then probability of all the actions are set to one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gyn_w3ulkyZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ea2c7-119b-4f0b-be41-24036a344e3f"
      },
      "source": [
        "print(env.observation_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zND5ArI8k_qQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1dca835-0e9a-40e9-b3d0-e7fedd56d2c9"
      },
      "source": [
        "stateSpaceSize = env.observation_space.n\n",
        "print(stateSpaceSize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_tp9YzRljnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5282ab5-7983-4ab0-945c-1aa77ba7ca7e"
      },
      "source": [
        "print(env.action_space)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozYwD0IXd9DH",
        "outputId": "489d97eb-29b4-41b3-9e48-34dee8658c62"
      },
      "source": [
        "actionSpaceSize = env.action_space.n\n",
        "print(actionSpaceSize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFGNZNowluz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bda89d6-000b-4bf5-ed34-cdfbca3b6d1e"
      },
      "source": [
        "for g in range(1,10,1):\n",
        "  print(\"sample from S:\",env.observation_space.sample(),\" ... \",\"sample from A:\",env.action_space.sample())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample from S: 10  ...  sample from A: 2\n",
            "sample from S: 6  ...  sample from A: 1\n",
            "sample from S: 0  ...  sample from A: 3\n",
            "sample from S: 8  ...  sample from A: 1\n",
            "sample from S: 15  ...  sample from A: 0\n",
            "sample from S: 15  ...  sample from A: 1\n",
            "sample from S: 9  ...  sample from A: 2\n",
            "sample from S: 4  ...  sample from A: 0\n",
            "sample from S: 8  ...  sample from A: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOQL5JxsmcEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c415f4-9449-46a8-e59c-df2d6b683aac"
      },
      "source": [
        "env.reset()\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLV6e43mmwx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9fd9d0-f983-4f25-f3a7-ca9f8015bddd"
      },
      "source": [
        "env.reset()\n",
        "exitCommand=False\n",
        "while not(exitCommand):\n",
        "  env.render()\n",
        "  print(\"Enter the action as an integer from 0 to\",env.action_space.n,\" (or exit): \")\n",
        "  userInput=input()\n",
        "  if userInput==\"exit\":\n",
        "    break\n",
        "  action=int(userInput)\n",
        "  (observation, reward, compute, probability) = env.step(action)\n",
        "  print(\"--> The result of taking action\",action,\"is:\")\n",
        "  print(\"     S=\",observation)\n",
        "  print(\"     R=\",reward)\n",
        "  print(\"     p=\",probability)\n",
        "\n",
        "  env.render()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Enter the action as an integer from 0 to 4  (or exit): \n",
            "0\n",
            "--> The result of taking action 0 is:\n",
            "     S= 0\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Left)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Enter the action as an integer from 0 to 4  (or exit): \n",
            "1\n",
            "--> The result of taking action 1 is:\n",
            "     S= 4\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "Enter the action as an integer from 0 to 4  (or exit): \n",
            "exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "mcPMYW4yeg5V",
        "outputId": "cd7addab-f7cd-47be-a693-792ef953fc5c"
      },
      "source": [
        "import pandas as pd\n",
        " \n",
        "data = {'Input':['0', '1', '2', '3'],\n",
        "        'Logic Action':['Left', 'Down', 'Right', 'Up']}\n",
        " \n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Input Logic Action\n",
              "0     0         Left\n",
              "1     1         Down\n",
              "2     2        Right\n",
              "3     3           Up"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37899f2e-c95d-4e50-ad28-4119970881c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input</th>\n",
              "      <th>Logic Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Down</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Up</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37899f2e-c95d-4e50-ad28-4119970881c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37899f2e-c95d-4e50-ad28-4119970881c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37899f2e-c95d-4e50-ad28-4119970881c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "OQizxbB8fKKw",
        "outputId": "0abad081-0593-44c2-a490-250040ff6a1e"
      },
      "source": [
        "data = {'Symbols':['S', 'H', 'F', 'G'],\n",
        "        'Meaning':['Start', 'Hole', 'Frozen', 'Goal']}\n",
        " \n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Symbols Meaning\n",
              "0       S   Start\n",
              "1       H    Hole\n",
              "2       F  Frozen\n",
              "3       G    Goal"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d78f53c-3b6d-4b56-9a53-296bb8fa2e1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Symbols</th>\n",
              "      <th>Meaning</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S</td>\n",
              "      <td>Start</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>H</td>\n",
              "      <td>Hole</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>F</td>\n",
              "      <td>Frozen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>G</td>\n",
              "      <td>Goal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d78f53c-3b6d-4b56-9a53-296bb8fa2e1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6d78f53c-3b6d-4b56-9a53-296bb8fa2e1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6d78f53c-3b6d-4b56-9a53-296bb8fa2e1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHN1ZP07hTZr"
      },
      "source": [
        "The agent should try to avoid all the holes in the map (4x4). Starting from the starting point, finding a suitable route to reach the goal point and get the reward (1) in the shortest time. Stopping at the State H (Hole) would lose the game immediately and receive nothing (0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmRwGwPoqw0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f70875f-d5bb-46de-a19d-47a312b4d99c"
      },
      "source": [
        "import random\n",
        "\n",
        "env.reset()\n",
        "exitCommand=False\n",
        "while not(exitCommand):\n",
        "  action=random.randint(0, 3)\n",
        "  (observation, reward, compute, probability) = env.step(action)\n",
        "  \n",
        "  print(\"--> The result of taking action\",action,\"is:\")\n",
        "  print(\"     S=\",observation)\n",
        "  print(\"     R=\",reward)\n",
        "  print(\"     p=\",probability)\n",
        "\n",
        "  env.render()\n",
        "\n",
        "  if compute and reward == 1 :\n",
        "    print(\"Success!\")\n",
        "    break\n",
        "  if compute and reward == 0 :\n",
        "    print(\"Hole!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> The result of taking action 3 is:\n",
            "     S= 0\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 1 is:\n",
            "     S= 4\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 2 is:\n",
            "     S= 5\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "Hole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9SpehErb_bY"
      },
      "source": [
        "We know that if we can find the optimal value functions, we can easily obtain optimal policies. We have $p(s',r|s,a)$, which represents a set of probabilities. For value function $v_{\\pi}$, we could start with $v_{\\pi}(s)=\\sum_{a}\\pi(a|s)\\sum_{s',r}p(s',r|s,a)[r+\\gamma v_{\\pi}(s')]$, where $\\pi(a|s)$ is the probability of taking action a in state s. Then we can pick up any initial value $v_0$ to implement iterative policy evaluation based on the Bellman equation ($v_{k+1}(s)=\\sum_{a}\\pi(a|s)\\sum_{s',r}p(s',r|s,a)[r+\\gamma v_{k}(s')]$). Each iteration of iterative strategy evaluation will update the value of each state once to generate a new approximate function $v_{k+1}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH597_HfeR7M"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_action_policy(stateSpaceSize, actionSpaceSize):\n",
        "    action = np.ones([stateSpaceSize, actionSpaceSize]) / actionSpaceSize\n",
        "    return action"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyr2bs3l5rPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3ebcf93-96dc-4a9e-981a-82f3ae330a88"
      },
      "source": [
        "import random\n",
        "\n",
        "env.reset()\n",
        "exitCommand=False\n",
        "while not(exitCommand):\n",
        "  env.render()\n",
        "  policy = random_action_policy(stateSpaceSize, actionSpaceSize)\n",
        "  action = np.random.choice(np.where(policy[observation] == policy[observation].max())[0])\n",
        "  (observation, reward, compute, probability) = env.step(action)\n",
        "  \n",
        "  print(\"--> The result of taking action\",action,\"is:\")\n",
        "  print(\"     S=\",observation)\n",
        "  print(\"     R=\",reward)\n",
        "  print(\"     p=\",probability)\n",
        "\n",
        "  env.render()\n",
        "\n",
        "  if compute and reward == 1 :\n",
        "    print(\"Success!\")\n",
        "    break\n",
        "  if compute and reward == 0 :\n",
        "    print(\"Hole!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 1 is:\n",
            "     S= 4\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 3 is:\n",
            "     S= 0\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Up)\n",
            "\u001b[41mS\u001b[0mFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 1 is:\n",
            "     S= 4\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "  (Down)\n",
            "SFFF\n",
            "\u001b[41mF\u001b[0mHFH\n",
            "FFFH\n",
            "HFFG\n",
            "--> The result of taking action 2 is:\n",
            "     S= 5\n",
            "     R= 0.0\n",
            "     p= {'prob': 1.0}\n",
            "  (Right)\n",
            "SFFF\n",
            "F\u001b[41mH\u001b[0mFH\n",
            "FFFH\n",
            "HFFG\n",
            "Hole!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHg7i_d3VnY3"
      },
      "source": [
        "def policy_evaluation(env, policy, gamma, theta, max_iter, if_print):\n",
        "  ## Note: stateSpaceSize = 16, actionSpaceSize = 4\n",
        "  ## Output -> V (4x4) -> Values of each state for the policy\n",
        "  iter = 0\n",
        "  V = np.zeros(stateSpaceSize)\n",
        "\n",
        "  ## i tracks the iteration numbers\n",
        "  for i in range (max_iter):\n",
        "    ## Start with delta = 0\n",
        "    delta = 0\n",
        "    ## Loop for each state in stateSpace\n",
        "    for s in range(stateSpaceSize):\n",
        "      Vs = 0\n",
        "      ## Loop for each actions in actionSpace\n",
        "      for a in range(actionSpaceSize):\n",
        "        action_probability = policy[s][a]\n",
        "        probability, next, reward, done = env.P[s][a][0]\n",
        "        ## Prob taking action * prob of env * (reward + gamma * value of next state)\n",
        "        Vs += action_probability * probability * (reward + gamma * V[next])\n",
        "      ## Update the delta\n",
        "      delta = max(delta, np.abs(V[s] - Vs))\n",
        "      V[s] = Vs\n",
        "    ## Loop until delta < theta\n",
        "    if delta < theta:\n",
        "      iter = i\n",
        "      break\n",
        "  if if_print:\n",
        "    print(\"Total iterations:\", i)\n",
        "  return V,i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGeoA_Mhv8fR",
        "outputId": "e712cb53-ab80-4c82-f1f2-49100a7de32f"
      },
      "source": [
        "policy = random_action_policy(stateSpaceSize, actionSpaceSize)\n",
        "V,iter_num = policy_evaluation(env.env, policy, 1, 1e-8, 100000000, True)\n",
        "V.resize((4,4))\n",
        "V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total iterations: 56\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01393977, 0.01163091, 0.02095297, 0.01047648],\n",
              "       [0.01624865, 0.        , 0.04075153, 0.        ],\n",
              "       [0.03480619, 0.08816993, 0.14205316, 0.        ],\n",
              "       [0.        , 0.17582037, 0.43929118, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PDPG1GJeGbX"
      },
      "source": [
        "def q_func(env, V, gamma):\n",
        "  Q = np.zeros([stateSpaceSize, actionSpaceSize])\n",
        "\n",
        "  for s in range(stateSpaceSize):\n",
        "    q = np.zeros(actionSpaceSize)\n",
        "    for a in range(actionSpaceSize):\n",
        "      probability, next, reward, done = env.P[s][a][0]\n",
        "      q[a] += probability * (reward + gamma * V[next])\n",
        "    Q[s] = q\n",
        "  \n",
        "  return Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8tobY5-fFIe",
        "outputId": "a49ecef9-acae-49c3-c939-e53e6439f2b7"
      },
      "source": [
        "policy = random_action_policy(stateSpaceSize, actionSpaceSize)\n",
        "V,iter_num = policy_evaluation(env.env, policy, 1, 1e-8, 100000000, False)\n",
        "Q = q_func(env.env, V, 1)\n",
        "Q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.01393977, 0.01624865, 0.01163091, 0.01393977],\n",
              "       [0.01393977, 0.        , 0.02095297, 0.01163091],\n",
              "       [0.01163091, 0.04075153, 0.01047648, 0.02095297],\n",
              "       [0.02095297, 0.        , 0.01047648, 0.01047648],\n",
              "       [0.01624865, 0.03480619, 0.        , 0.01393977],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.14205316, 0.        , 0.02095297],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.03480619, 0.        , 0.08816993, 0.01624865],\n",
              "       [0.03480619, 0.17582037, 0.14205316, 0.        ],\n",
              "       [0.08816993, 0.43929118, 0.        , 0.04075153],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.17582037, 0.43929118, 0.08816993],\n",
              "       [0.17582037, 0.43929118, 1.        , 0.14205316],\n",
              "       [0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwpDzV-edauS"
      },
      "source": [
        "We have the env P and a value function. We want to find a better policy $\\pi'$ so that $v_{\\pi'}(s)\\geq v_{\\pi}$. Base on this, we could select at each state the action that appears best. $\\pi'(s)$ could be express as $\\pi'(s)=\\arg\\max_{a}\\sum_{s',r}p(s',r|s,a)[r+\\gamma v_{\\pi}(s')]$. Now, the new greedy policy could better or equal to the original policy based on the policy improvement theorem. After that, we will do policy iteration, value iteration based on the previous improvement steps. Starting from a original policy, repeating policy evaluation and policy improvement to find the suitable policy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHMu4Zq-lUzx"
      },
      "source": [
        "def policy_improve(env,V,gamma) :\n",
        "  max_num = 0\n",
        "  new_policy = np.zeros([stateSpaceSize, actionSpaceSize]) / actionSpaceSize\n",
        "\n",
        "  for s in range(stateSpaceSize):\n",
        "    max_num = max(q_func(env, V, gamma)[s])\n",
        "              \n",
        "    if max_num == 0 :\n",
        "      continue\n",
        "\n",
        "    best_action = np.where(q_func(env, V, 1)[s] == max_num)[0]\n",
        "    length = len(best_action)\n",
        "    for i in best_action :\n",
        "      new_policy[s][i] = 1/length\n",
        "  \n",
        "  return new_policy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWS4OwdbwJ2r"
      },
      "source": [
        "def policy_iteration(env, gamma, theta, max_iter) :\n",
        "  over_iter = 0\n",
        "  Eval_iter = 0\n",
        "  stateSpaceSize = env.observation_space.n\n",
        "  actionSpaceSize = env.action_space.n\n",
        "  ## Step 1: Initialization \n",
        "  policy = random_action_policy(stateSpaceSize, actionSpaceSize)\n",
        "\n",
        "  ## i tracks the overall iteration numbers\n",
        "  for i in range(max_iter):\n",
        "    ## Step 2: Policy Evaluation \n",
        "    V,k = policy_evaluation(env, policy, gamma, theta, 10000, False)\n",
        "    Eval_iter +=k\n",
        "    ## Step 3: Policy Improvement\n",
        "    new_policy = policy_improve(env,V,gamma)\n",
        "    ## Check if two policies are the same\n",
        "    N,v = policy_evaluation(env, new_policy, gamma, theta, 10000, False)\n",
        "    if (new_policy == policy).all():\n",
        "      break;\n",
        "    #if np.max(abs(V - N)) < 1e-6:\n",
        "    #  over_iter = i\n",
        "    #  break;\n",
        "    over_iter = i\n",
        "    policy = new_policy.copy()\n",
        "  \n",
        "  print(\"Overall policy iteration steps :\", over_iter)\n",
        "  print(\"Evaluation steps. :\", Eval_iter)\n",
        "\n",
        "  return policy, V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNY6VZIP_KDl",
        "outputId": "d05b8eb1-f2ce-4256-b6aa-0cfeee57241c"
      },
      "source": [
        "policy_PI, V_PI = policy_iteration(env.env, 1, 1e-8, 10)\n",
        "V_PI.resize((4,4))\n",
        "V_PI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall policy iteration steps : 9\n",
            "Evaluation steps. : 2766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1.],\n",
              "       [1., 0., 1., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [0., 1., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB8_fuY5-yUU"
      },
      "source": [
        "def value_iteration(ebv,gamma,theta,max_iter) :\n",
        "  stateSpaceSize = env.observation_space.n\n",
        "  actionSpaceSize = env.action_space.n\n",
        "  V = np.zeros(stateSpaceSize)\n",
        "  ## i tracks the iteration numbers\n",
        "  for i in range (max_iter):\n",
        "    ## Start with delta = 0\n",
        "    delta = 0\n",
        "    ## Loop for each state in stateSpace\n",
        "    for s in range(stateSpaceSize):\n",
        "      Vs = V[s]\n",
        "      V[s] = max(q_func(env, V, 1)[s])\n",
        "      delta = max(delta, np.abs(V[s] - Vs))\n",
        "\n",
        "    if delta < theta:\n",
        "      break\n",
        "      \n",
        "  print(\"Overall policy iteration steps :\", i)\n",
        "\n",
        "  policy = policy_improve(env,V,gamma)\n",
        "  return policy,V"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN88uotA-7BF",
        "outputId": "bcc53cce-b0c1-4ea1-bec0-15622f87a24e"
      },
      "source": [
        "policy_VI, V_VI = value_iteration(env, 1, 1e-8, 2000)\n",
        "V_VI.resize((4,4))\n",
        "V_VI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall policy iteration steps : 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1.],\n",
              "       [1., 0., 1., 0.],\n",
              "       [1., 1., 1., 0.],\n",
              "       [0., 1., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBIiyyAnGxcj"
      },
      "source": [
        "We can see that the iteration time for value_iteration is shorter than policy_iteration. Since we do not need to go through policy improvement in each iteration. It could save a lot of time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62H_D1J7H12z",
        "outputId": "becc732b-8408-4c75-96b3-054f11afda5c"
      },
      "source": [
        "import random\n",
        "\n",
        "env.reset()\n",
        "exitCommand=False\n",
        "while not(exitCommand):\n",
        "  policy = policy_VI\n",
        "  action = np.random.choice(np.where(policy[observation] == policy[observation].max())[0])\n",
        "  (observation, reward, compute, probability) = env.step(action)\n",
        "\n",
        "  if compute and reward == 1 :\n",
        "    env.render()\n",
        "    print(\"Success!\")\n",
        "    break\n",
        "  if compute and reward == 0 :\n",
        "    print(\"Hole!\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (Right)\n",
            "SFFF\n",
            "FHFH\n",
            "FFFH\n",
            "HFF\u001b[41mG\u001b[0m\n",
            "Success!\n"
          ]
        }
      ]
    }
  ]
}